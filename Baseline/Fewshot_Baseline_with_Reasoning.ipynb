{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f9e4696c6d44dd09235a8ec522b4489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41bd0327cd104b06a4099bbb0fbea1b3",
              "IPY_MODEL_c8fc934a1e224424a258dd425a482390",
              "IPY_MODEL_54f6e1e0c2a740b88fa4e1d464feaafa"
            ],
            "layout": "IPY_MODEL_18c5a376b3264d278b1d12dcc0b825b5"
          }
        },
        "41bd0327cd104b06a4099bbb0fbea1b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641442134bdd4858b0f725273b862523",
            "placeholder": "​",
            "style": "IPY_MODEL_23b1b477a5ce416fb756cc2033183f4e",
            "value": "Downloading builder script: 100%"
          }
        },
        "c8fc934a1e224424a258dd425a482390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08ec416e7c9c47b5b9e60fcee6b7d44c",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36370ac6a3124bd3929abe19021c36e2",
            "value": 6270
          }
        },
        "54f6e1e0c2a740b88fa4e1d464feaafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd590b3bb65643dcb592546b696077a6",
            "placeholder": "​",
            "style": "IPY_MODEL_929b622be16e4332bf04975767ed30f9",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 219kB/s]"
          }
        },
        "18c5a376b3264d278b1d12dcc0b825b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "641442134bdd4858b0f725273b862523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23b1b477a5ce416fb756cc2033183f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08ec416e7c9c47b5b9e60fcee6b7d44c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36370ac6a3124bd3929abe19021c36e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd590b3bb65643dcb592546b696077a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929b622be16e4332bf04975767ed30f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56156932c2cc402c93b08e2ef139d545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c531e05f5b504a1d931cbe27c6718392",
              "IPY_MODEL_5dd8f777dd3a46c7b08988080a4b2ded",
              "IPY_MODEL_95fa38e6278a45bb9831a31fd7258075"
            ],
            "layout": "IPY_MODEL_c9e4914f68014a7187d733b845a768bf"
          }
        },
        "c531e05f5b504a1d931cbe27c6718392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17d58dbed561496880f5d463887b60e8",
            "placeholder": "​",
            "style": "IPY_MODEL_70fded085143458dacdd87b39668af4f",
            "value": "Downloading builder script: 100%"
          }
        },
        "5dd8f777dd3a46c7b08988080a4b2ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0da78aa6071648bbae7546a2f39de68e",
            "max": 7950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_385ea180ebe540169aea4c5c6ab896bf",
            "value": 7950
          }
        },
        "95fa38e6278a45bb9831a31fd7258075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3915679bcb534a6c8ab6da78a07fdb81",
            "placeholder": "​",
            "style": "IPY_MODEL_2afa67c1ea904c47942cc6b7f7388f32",
            "value": " 7.95k/7.95k [00:00&lt;00:00, 410kB/s]"
          }
        },
        "c9e4914f68014a7187d733b845a768bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d58dbed561496880f5d463887b60e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70fded085143458dacdd87b39668af4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0da78aa6071648bbae7546a2f39de68e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "385ea180ebe540169aea4c5c6ab896bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3915679bcb534a6c8ab6da78a07fdb81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2afa67c1ea904c47942cc6b7f7388f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzK2Gvssjxd3",
        "outputId": "8818668e-29da-4c94-8ffd-11ae8d8627ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: together in /usr/local/lib/python3.10/dist-packages (1.1.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.10/dist-packages (from together) (3.9.5)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from together) (8.1.7)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from together) (0.2.0)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.10/dist-packages (from together) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from together) (1.25.2)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from together) (10.3.0)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from together) (14.0.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from together) (2.7.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from together) (2.31.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.10/dist-packages (from together) (4.66.4)\n",
            "Requirement already satisfied: typer<0.13,>=0.9 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (4.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets\n",
        "!pip install together"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datasets import load_dataset, Dataset\n",
        "# from trl import SFTTrainer\n",
        "!pip install -U huggingface_hub\n",
        "from huggingface_hub import login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VtbC7ouj0Nw",
        "outputId": "e7a5252f-09a6-4a6f-c008-3f9ab95d8fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=\"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\",add_to_git_credential=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3pN4bPQkFDp",
        "outputId": "260d92bf-c126-4ba5-b212-844ac614356b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: write).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "dataset_name = \"aqua_rat\"\n",
        "test_dataset = load_dataset(dataset_name, split=\"test\")\n"
      ],
      "metadata": {
        "id": "P7Ycj67PkLuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1):\n",
        "  print(test_dataset[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yonY8J7kPkf",
        "outputId": "928a08e5-77a3-4557-cb91-6ee4a29dceff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'A car is being driven, in a straight line and at a uniform speed, towards the base of a vertical tower. The top of the tower is observed from the car and, in the process, it takes 10 minutes for the angle of elevation to change from 45° to 60°. After how much more time will this car reach the base of the tower?', 'options': ['A)5(√3 + 1)', 'B)6(√3 + √2)', 'C)7(√3 – 1)', 'D)8(√3 – 2)', 'E)None of these'], 'rationale': 'Explanation :\\nLet the height of the building be h. Initially, he was at an angle of 450. tan 45 = h/distance between car and tower. h = distance between car and tower (since tan 45 = 1).\\nNow, after 10 minutes, it travelled a certain distance, and angle changed to 600.\\ntan 60 = h/x x = h/√3\\nSo, in 10 minutes, it has travelled a distance of h – x = h - h/√3.\\n10 minutes = h *( 1 – 1√3)\\nh can be travelled in 10 / (1 – 1√3).\\nTo travel a distance of x, which is h/√3, it takes :\\nh = 10 / (1 – 1/√3)\\nh / √3 = 10/ √3 * (1 – 1/√3). Multiply numerator and denominator by 1 + √3 ( conjugate of 1 - √3). We get, x = h/√3 = 10 (1 + √3) / 2 = 5* (1 + √3)\\nSo, it takes 5(1 + √3) minutes to reach the base of the tower.\\nAnswer : A', 'correct': 'A'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from together import Together\n",
        "TOGETHER_API_KEY = \"3f06bb7945192b6e58e9d4acd1d265fe51a1478015fb5cac5d67c3ca274b3c94\"\n",
        "client = Together(api_key=TOGETHER_API_KEY)\n"
      ],
      "metadata": {
        "id": "5c7cd7KPkWS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# from datasets import load_dataset, Dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def extract_answer_option(text):\n",
        "    \"\"\"\n",
        "    Extract the correct answer option from the reasoning\n",
        "    \"\"\"\n",
        "    # Regular expression patterns to match the given cases\n",
        "    pattern_exp = '\\s*\\(?\\s*([A-Ea-e])\\s*\\)'\n",
        "    correct_answer_patterns = [\n",
        "        r'The\\s*correct\\s*answer\\s*option\\s*is',\n",
        "        r'The\\s*correct\\s*answer\\s*is',\n",
        "        r'The\\s*correct\\s*answer\\s*is\\s*option'\n",
        "    ]\n",
        "\n",
        "    patterns = [re.compile(pattern  + pattern_exp, re.IGNORECASE) for pattern in correct_answer_patterns]\n",
        "\n",
        "    # Search for the patterns in the text in the specified order\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            return match.group(1).upper()\n",
        "\n",
        "    # If no match is found, return None\n",
        "    return 'A'\n",
        "\n",
        "def load_dataset_inference(test_dataset):\n",
        "    \"\"\"\n",
        "    Load and return the dataset for inference\n",
        "    \"\"\"\n",
        "    if len(test_dataset) == 0:\n",
        "      dataset_name = \"aqua_rat\"\n",
        "      test_dataset = load_dataset(dataset_name, split=\"test\")\n",
        "    return test_dataset\n",
        "\n",
        "def compute_metrics(true_labels, pred_labels):\n",
        "    \"\"\"\n",
        "    Load and return the dataset for inference\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(true_labels, pred_labels)\n",
        "    f1 = f1_score(true_labels, pred_labels, average='macro') #TOOD: check macro\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1_score': f1\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def construct_prompt(question, options):\n",
        "    \"\"\"\n",
        "    Generate a formatted prompt for a math problem.\n",
        "\n",
        "    :param question: A string representing the math question.\n",
        "    :param options: A list of strings representing the possible answer options.\n",
        "    :return: A formatted string representing the complete problem statement.\n",
        "    \"\"\"\n",
        "    #prompt = \"Calculate the answer for the following math problem and return the option that matches with the answer in the options list. Please only return the character representing an option(A or B or C or D or E) from the options list \\n\\n\"\n",
        "    prompt = \"Calculate the answer for the following math problem and return the option that matches with the answer in the options list. Please only return the character representing an option(A or B or C or D or E) from the options list \\n\\n\"\n",
        "    prompt = \"You are an mathematical assistant that helps users with the Algebra questions. You are asked a multi-choice question along with the answer options - A, B, C, D, E. \\n\"\n",
        "    prompt += \"Look at the below sample examples provided (question, answer options, expected output), focus on the expected output and its format (i.e reasoning, conclusion and final answer option selection). \\n\"\n",
        "    prompt += \"Example Question 1 : Two friends plan to walk along a 43-km trail, starting at opposite ends of the trail at the same time. If Friend P's rate is 15% faster than Friend Q's, how many kilometers will Friend P have walked when they pass each other? \\n\"\n",
        "    prompt += \"Options for Example Question 1:  ['A)21', 'B)21.5', 'C)22', 'D)22.5', 'E)23'] \\n\"\n",
        "    prompt += \"Expected Output for Example Question 1: If Q complete x kilometers, then P completes 1.15x kilometers.\\nx + 1.15x = 43\\n2.15x=43\\nx = 43/2.15 = 20\\nThen P will have have walked 1.15*20=23 km. The correct answer option is E) 23 \\n\"\n",
        "    prompt += \"Example Question 2 : Three birds are flying at a fast rate of 900 kilometers per hour. What is their speed in miles per minute? [1km = 0.6 miles] \\n\"\n",
        "    prompt += \"Options for Example Question 2:  ['A)32400', 'B)6000', 'C)600', 'D)60000', 'E)10'] \\n\"\n",
        "    prompt += \"Expected Output for Example Question 2: To calculate the equivalent of miles in a kilometer\\n0.6 kilometers = 1 mile\\n900 kilometers = (0.6)*900 = 540 miles\\nIn 1 hour there are 60 minutes\\nSpeed in miles/minutes = 60 * 540 = 32400. The correct answer option is A) 32400 \\n\"\n",
        "    prompt += \"Now, Solve the below provided question and choose the correct option. Provide the reasoning and final answer option similar to the sample questions shared. Provide the output in a format that is same as the sample questions outputs. Additionally, follow the below instructions without fail. \\n\"\n",
        "    prompt += \"2) Provide the answer option response in the format : \\\"The correct answer option is ({})\\\" \\n\"\n",
        "    prompt += f\"Question: '{question}'\\n\\n\"\n",
        "    prompt += \"Options: \"\n",
        "    prompt += \", \".join(options)\n",
        "    return prompt\n",
        "\n",
        "#TODO: re-do logic if the request fails, rate-limiting etc, how do we handle these? how many retries etc?.\n",
        "def together_inference(prompt):\n",
        "    \"\"\"\n",
        "    Inference from the LlaMA-2 7b instruct model using together API.\n",
        "\n",
        "    :param prompt: A string representing the constructed prompt\n",
        "    :return: A formatted string representing the complete api response for the input prompt\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "          model=\"codellama/CodeLlama-7b-Instruct-hf\", #TODO: model type\n",
        "          messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "      )\n",
        "    print(f'Together API response is: {response.choices[0].message.content}')\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# #TODO: we can parallelize these. multiple threads etc to get faster results.\n",
        "# def zero_shot_inputs_to_llm():\n",
        "#     train, val, test = load_dataset()\n",
        "#     true_labels = []\n",
        "\n",
        "#     prompts = []\n",
        "#     for i in range(len(test)):\n",
        "#       question = test[\"question\"][i]\n",
        "#       true_label = test[\"correct\"][i]\n",
        "#       options = test[\"options\"][i]\n",
        "\n",
        "#       prompt = construct_prompt(question, options)\n",
        "#       response = together_inference(prompt)\n",
        "\n",
        "#       pred_label = extract_answer_option(response)\n",
        "\n",
        "#       true_labels.append(true_label)\n",
        "#       pred_labels.append(pred_label)\n",
        "#       print(f'Prompt is {prompt} and response is {response}')\n",
        "#       print(f'True label is {true_label} and pred label is {pred_label}')\n",
        "#       print('--------------------------------------------------------------')\n",
        "\n",
        "# def zero_shot_inference(prompts):\n",
        "#   api_responses = []\n",
        "#   for prompt in prompts:\n",
        "#     response = together_inference(prompt)\n",
        "#     api_responses.append(response)\n",
        "\n",
        "#     eval_metrics = compute_metrics(true_labels, pred_labels)\n",
        "#     print(f\"Accuracy is {eval_metrics['accuracy']} and F1 score is {eval_metrics['f1_score']}\")"
      ],
      "metadata": {
        "id": "yg8x4DX-kYLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge_score\n",
        "!pip install bert_score\n",
        "import evaluate\n",
        "rouge = evaluate.load('rouge')\n",
        "bertscore = evaluate.load(\"bertscore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9f9e4696c6d44dd09235a8ec522b4489",
            "41bd0327cd104b06a4099bbb0fbea1b3",
            "c8fc934a1e224424a258dd425a482390",
            "54f6e1e0c2a740b88fa4e1d464feaafa",
            "18c5a376b3264d278b1d12dcc0b825b5",
            "641442134bdd4858b0f725273b862523",
            "23b1b477a5ce416fb756cc2033183f4e",
            "08ec416e7c9c47b5b9e60fcee6b7d44c",
            "36370ac6a3124bd3929abe19021c36e2",
            "cd590b3bb65643dcb592546b696077a6",
            "929b622be16e4332bf04975767ed30f9",
            "56156932c2cc402c93b08e2ef139d545",
            "c531e05f5b504a1d931cbe27c6718392",
            "5dd8f777dd3a46c7b08988080a4b2ded",
            "95fa38e6278a45bb9831a31fd7258075",
            "c9e4914f68014a7187d733b845a768bf",
            "17d58dbed561496880f5d463887b60e8",
            "70fded085143458dacdd87b39668af4f",
            "0da78aa6071648bbae7546a2f39de68e",
            "385ea180ebe540169aea4c5c6ab896bf",
            "3915679bcb534a6c8ab6da78a07fdb81",
            "2afa67c1ea904c47942cc6b7f7388f32"
          ]
        },
        "id": "RiqDcEsJkamt",
        "outputId": "1c67ab85-333f-46d1-b914-f0c01b720d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81.9/84.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.2\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.2)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=82ab8a531477d3f0d54d0b80c5605bf0906b47e211665f2685e3c001beb95c83\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.0.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.40.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert_score)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert_score\n",
            "Successfully installed bert_score-0.3.13 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f9e4696c6d44dd09235a8ec522b4489"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.95k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56156932c2cc402c93b08e2ef139d545"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder_path = \"/content/drive/My Drive/AQua_RAT/\"\n",
        "!mkdir -p folder_path\n",
        "file_name = \"FewshotPredictionsWithReasoning_AQUARAT3.csv\"\n",
        "file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "# Function to authenticate Google Drive and upload CSV\n",
        "def upload_to_drive(csv_file):\n",
        "  if not os.path.exists(file_path):\n",
        "    # Create the file if it doesn't exist\n",
        "    with open(file_path, 'w') as f:\n",
        "        # Write header to the CSV file\n",
        "        f.write(\"question,options,true_rationale,true_answer,predicted_rationale,predicted_answer,rouge_L,rouge_1,bertscore\\n\")\n",
        "    print(f\"File {file_name} created in {folder_path}\")\n",
        "  else:\n",
        "    print(f\"File {file_name} already exists in {folder_path}\")\n",
        "    return\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XScCtsHQkdI-",
        "outputId": "9c26452a-d63e-41b4-ec60-2fe20388b316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "def get_predicted_few_shot_data(test_df, csv_file):\n",
        "  upload_to_drive(csv_file)\n",
        "  # Load existing data from CSV\n",
        "  existing_data = pd.read_csv(csv_file)\n",
        "  start_point = len(existing_data)\n",
        "  print(existing_data[start_point - 1:])\n",
        "  print('Start point is ' + str(start_point))\n",
        "\n",
        "\n",
        "  batch_size = 5\n",
        "  for i in range(start_point, len(test_df), batch_size):\n",
        "    new_rows = []\n",
        "    # Process each batch\n",
        "    for j in range(batch_size):\n",
        "      if i + j >= len(test_df):\n",
        "        break\n",
        "\n",
        "      question = test_df.loc[i+j, 'question']\n",
        "      options = test_df.loc[i+j, 'options']\n",
        "      rationale = test_df.loc[i+j, 'rationale']\n",
        "      correct = test_df.loc[i+j, 'correct']\n",
        "      print(question)\n",
        "\n",
        "      if i+j in set([36,60,80,137,186,191,245,246]):\n",
        "        new_row = {'question': question, 'options': options, 'true_rationale': rationale, 'true_answer': correct,\n",
        "                  'predicted_rationale': None, 'predicted_answer':None, 'rouge_L': None, 'rouge_1': None, 'bertscore': None}\n",
        "        new_rows.append(new_row)\n",
        "        continue\n",
        "      # Handle API timeout errors\n",
        "      try:\n",
        "          prompt = construct_prompt(question, options)\n",
        "          predicted_rationale = together_inference(prompt)\n",
        "          predicted_answer = extract_answer_option(predicted_rationale)\n",
        "          # Create dictionary representing new row\n",
        "          res = rouge.compute(predictions=[predicted_rationale], references=[rationale])\n",
        "          rL = res['rougeL']\n",
        "          r1 = res['rouge1']\n",
        "          try:\n",
        "            res = bertscore.compute(predictions=[predicted_rationale], references=[rationale], model_type=\"distilbert-base-uncased\")\n",
        "          except:\n",
        "            res = {'f1': [np.nan], 'precision':[np.nan]}\n",
        "          f1 = res['f1'][0]\n",
        "          p = res['precision'][0]\n",
        "\n",
        "          # Create dictionary representing new row\n",
        "          new_row = {'question': question, 'options': options, 'true_rationale': rationale, 'true_answer': correct,\n",
        "                  'predicted_rationale': predicted_rationale, 'predicted_answer': predicted_answer, 'rouge_L': rL, 'rouge_1': r1, 'bertscore': f1}\n",
        "          new_rows.append(new_row)\n",
        "      except Exception as error:\n",
        "          # Upload to Google Drive before exiting\n",
        "          print(error)\n",
        "          upload_to_drive(csv_file)\n",
        "          print(\"API Error occurred. Saving progress and exiting.\")\n",
        "          new_data = pd.DataFrame(new_rows)\n",
        "          new_data.to_csv(csv_file, index=False, mode='a', header=not os.path.exists(csv_file))\n",
        "          return\n",
        "      print(f\"Inference done for question {i + j + 1}\")\n",
        "\n",
        "    new_data = pd.DataFrame(new_rows)\n",
        "    new_data.to_csv(csv_file, index=False, mode='a', header=not os.path.exists(csv_file))\n",
        "    time.sleep(5)\n",
        "  print(f\"Updated {csv_file} with new inferences.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4QwJYGSTklfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.DataFrame(load_dataset_inference(test_dataset))\n",
        "get_predicted_few_shot_data(test_data, file_path)"
      ],
      "metadata": {
        "id": "Bf6epCx9kpGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9261d385-0dd2-4f58-f4df-c11406c9a6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File FewshotPredictionsWithReasoning_AQUARAT3.csv already exists in /content/drive/My Drive/AQua_RAT/\n",
            "                                              question  \\\n",
            "245  There is a 90% chance that a registered voter ...   \n",
            "\n",
            "                                               options  \\\n",
            "245  ['A)26.2%', 'B)32.8%', 'C)43.7%', 'D)59.0%', '...   \n",
            "\n",
            "                                        true_rationale true_answer  \\\n",
            "245  The probability that four of five voted is :\\n...           E   \n",
            "\n",
            "    predicted_rationale predicted_answer  rouge_L  rouge_1  bertscore  \n",
            "245                 NaN              NaN      NaN      NaN        NaN  \n",
            "Start point is 246\n",
            "Alice wants to put up fencing around three sides of her rectangular yard and leave one side of 10 meters unfenced. If the yard has an area of 240 square meters, how many meters of fencing does she need?\n",
            "John would make the 3-letter codes with diffenrent 5 vowels and 20 consonants with the condition that the middle letter must be vowel and the first letter and the third letter must be different from each other and are both consonant. How many different codes can be made?\n",
            "Together API response is:   The correct answer option is C) 2,100.\n",
            "\n",
            "Reasoning:\n",
            "\n",
            "To find the number of different codes that can be made, we need to consider the following conditions:\n",
            "\n",
            "1. The middle letter must be a vowel.\n",
            "2. The first letter and the third letter must be different from each other and are both consonants.\n",
            "\n",
            "Let's consider the first condition. There are 5 vowels in the English alphabet, so we can choose any one of them as the middle letter.\n",
            "\n",
            "Now, let's consider the second condition. There are 20 consonants in the English alphabet, so we can choose any 2 of them as the first and third letters.\n",
            "\n",
            "Since the first letter and the third letter must be different from each other, we can choose any 2 different consonants from the 20 consonants.\n",
            "\n",
            "Therefore, the total number of different codes that can be made is 5 x 20 = 100.\n",
            "\n",
            "Since there are 100 different codes that can be made, the correct answer option is C) 2,100.\n",
            "Inference done for question 248\n",
            "What is the sum of three consecutive integers whose product can be expressed as 727+728+729.\n",
            "Together API response is:   The correct answer option is C) 36.\n",
            "\n",
            "Reasoning:\n",
            "The sum of three consecutive integers whose product can be expressed as 727+728+729 is 36.\n",
            "\n",
            "To find the sum, we can use the fact that the product of three consecutive integers is equal to the sum of the first two integers plus the third integer, multiplied by 2.\n",
            "\n",
            "727 + 728 + 729 = 727 + 728 + 729 x 2 = 36 x 2 = 72\n",
            "\n",
            "Therefore, the sum of three consecutive integers whose product can be expressed as 727+728+729 is 36.\n",
            "\n",
            "The correct answer option is C) 36.\n",
            "Inference done for question 249\n",
            "The capacity of a tank of dimensions (8 m × 6 m × 2.5 m) is\n",
            "Together API response is:   The correct answer option is B) 1200 litres.\n",
            "\n",
            "Reasoning:\n",
            "The volume of the tank can be calculated using the formula:\n",
            "\n",
            "Volume = Length × Width × Height\n",
            "\n",
            "In this case, the length, width, and height of the tank are 8 m, 6 m, and 2.5 m, respectively. Plugging these values into the formula, we get:\n",
            "\n",
            "Volume = 8 m × 6 m × 2.5 m = 120 cubic meters\n",
            "\n",
            "Since there are 1000 liters in a cubic meter, we can convert the volume to liters as follows:\n",
            "\n",
            "120 cubic meters = 120,000 liters\n",
            "\n",
            "Therefore, the correct answer option is B) 1200 litres.\n",
            "Inference done for question 250\n",
            "The population of a city is 5265526. If there are 4169516 adults in the city, how many children are there in the city?\n",
            "Together API response is:   The correct answer option is C) 1085961.\n",
            "\n",
            "Reasoning:\n",
            "The question asks us to find the number of children in a city based on the population and the number of adults. We can use the formula:\n",
            "\n",
            "Number of children = Total population - Number of adults\n",
            "\n",
            "In this case, the total population is 5265526 and the number of adults is 4169516. Therefore, the number of children is:\n",
            "\n",
            "Number of children = 5265526 - 4169516 = 1085961\n",
            "\n",
            "Therefore, the correct answer option is C) 1085961.\n",
            "Inference done for question 251\n",
            "It takes a worker 9 minutes to drive from home to work at an average rate of 20 kilometers per hour. How many minutes will it take the worker to cycle from home to work along the same route at an average rate of 6 kilometers per hour?\n",
            "Together API response is:   The correct answer option is E) 40.\n",
            "\n",
            "Reasoning:\n",
            "\n",
            "To solve this question, we need to find the time it takes for the worker to cycle from home to work along the same route at an average rate of 6 kilometers per hour. We know that it takes the worker 9 minutes to drive from home to work at an average rate of 20 kilometers per hour.\n",
            "\n",
            "Let's first convert the rate of cycling from kilometers per hour to minutes per kilometer:\n",
            "\n",
            "6 km/h = 1/6 km/min\n",
            "\n",
            "Now, we can use the formula for time = distance / rate to find the time it takes to cycle from home to work:\n",
            "\n",
            "Time = Distance / Rate\n",
            "\n",
            "Distance = 20 km (distance to work)\n",
            "Rate = 6 km/min (rate of cycling)\n",
            "\n",
            "Time = 20 km / 6 km/min = 3.33 minutes\n",
            "\n",
            "Therefore, it will take the worker 3.33 minutes to cycle from home to work along the same route at an average rate of 6 kilometers per hour.\n",
            "\n",
            "The correct answer option is E) 40, which is the nearest whole number to 3.33 minutes.\n",
            "Inference done for question 252\n",
            "Two friends are eating a jar full of candies. Had P eaten alone, it would have taken him 10 minutes to finish the candies in the jar. Had Q eaten alone, it would have taken her 5 minutes to finish half the jar. Since both of them are eating simultaneously, how many minutes would it take them to empty the jar?\n",
            "Together API response is:   The correct answer option is B) 5.\n",
            "\n",
            "Reasoning:\n",
            "\n",
            "Let's call the time taken by P to finish the candies in the jar x minutes. Since P eats alone, it would take him 10 minutes to finish the candies in the jar.\n",
            "\n",
            "Similarly, let's call the time taken by Q to finish half the jar y minutes. Since Q eats alone, it would take her 5 minutes to finish half the jar.\n",
            "\n",
            "Since both P and Q are eating simultaneously, the total time taken by both of them to empty the jar would be the sum of their individual times.\n",
            "\n",
            "x + y = 10 + 5 = 15 minutes\n",
            "\n",
            "Therefore, the correct answer option is B) 5.\n",
            "Inference done for question 253\n",
            "A grocery sells a bag of ice for $1.25, and makes 20% profit. If it sells 500 bags of ice, how much total profit does it make?\n",
            "Together API response is:   The correct answer option is C) 225.\n",
            "\n",
            "Reasoning:\n",
            "The question states that the grocery sells a bag of ice for $1.25 and makes 20% profit. To find the total profit, we need to calculate the profit per bag and then multiply it by the number of bags sold.\n",
            "\n",
            "Profit per bag = (20% of $1.25) = $0.25\n",
            "Total profit = Profit per bag x Number of bags sold = $0.25 x 500 = $125\n",
            "\n",
            "Therefore, the correct answer option is C) 225.\n",
            "Inference done for question 254\n",
            "Updated /content/drive/My Drive/AQua_RAT/FewshotPredictionsWithReasoning_AQUARAT3.csv with new inferences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "def get_data_from_csv(file_path):\n",
        "  if os.path.exists(file_path):\n",
        "    inferenced_data = pd.read_csv(file_path)\n",
        "    return inferenced_data\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "def compute_metrics(true_labels, pred_labels):\n",
        "    \"\"\"\n",
        "    Load and return the dataset for inference\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(true_labels, pred_labels)\n",
        "    f1 = f1_score(true_labels, pred_labels, average='macro') #TOOD: check macro\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1_score': f1\n",
        "    }\n",
        "\n",
        "def get_evaluation_metrics(inferenced_data):\n",
        "  true_answers = inferenced_data['true_answer'].tolist()\n",
        "  predicted_answers = inferenced_data['predicted_answer'].tolist()\n",
        "  accuracy = accuracy_score(true_answers, predicted_answers)\n",
        "  f1 = f1_score(true_answers, predicted_answers, average='macro')\n",
        "  rouge_L, rouge_1, bertscore = inferenced_data['rouge_L'].mean(), inferenced_data['rouge_1'].mean(), inferenced_data['bertscore'].mean()\n",
        "  print(accuracy)\n",
        "  print(f1)\n",
        "  print(rouge_L)\n",
        "  print(rouge_1)\n",
        "  print(bertscore)\n",
        "\n",
        "inferenced_data = get_data_from_csv(file_path)\n",
        "\n",
        "get_evaluation_metrics(inferenced_data)"
      ],
      "metadata": {
        "id": "SEnvK92skqdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd761a30-bb93-4b96-9de1-1c847fccb360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23228346456692914\n",
            "0.1622947177221106\n",
            "0.18770829522742719\n",
            "0.24680186379018249\n",
            "0.7816528532563186\n"
          ]
        }
      ]
    }
  ]
}